# Core Configuration
SERVER_PORT=3001
STORAGE_DIR=/app/server/storage
UID=1001 # User ID that the AnythingLLM process runs as inside the container.
GID=1001 # Group ID that the AnythingLLM process runs as inside the container.

# LLM Configuration (Choose your preferred provider and model)
LLM_PROVIDER=gemini # Example: openai, gemini, groq, azure, local, anthropic, ollama, custom
GEMINI_API_KEY=YOUR_GEMINI_API_KEY_HERE # Get your key from Google AI Studio
GEMINI_LLM_MODEL_PREF=gemini-pro-latest # Preferred Gemini model (e.g., gemini-pro-latest, gemini-flash-latest)

# Other LLM API Keys (Uncomment and fill as needed for other providers)
# OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
GROQ_API_KEY=YOUR_GROQ_API_KEY_HERE # Get your key from Groq console
# ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY_HERE
# AZURE_OPENAI_API_KEY=YOUR_AZURE_OPENAI_API_KEY_HERE
# AZURE_OPENAI_ENDPOINT=YOUR_AZURE_OPENAI_ENDPOINT_HERE
# HF_TOKEN=YOUR_HUGGINGFACE_TOKEN_HERE

# Embedding Engine Configuration
EMBEDDING_ENGINE=native # Example: native, openai, cohere, huggingface, ollama, custom

# Vector Database Configuration
VECTOR_DB=lancedb # Example: lancedb, chromadb, pinecone, qdrant, weaviate, zod

# Security Configuration (Generate strong, random strings for these)
JWT_SECRET=GENERATE_A_STRONG_RANDOM_STRING_HERE
SIG_KEY=GENERATE_A_STRONG_RANDOM_STRING_HERE
SIG_SALT=GENERATE_A_STRONG_RANDOM_STRING_HERE

# Admin User (Optional: Setup via UI is recommended after initial deployment)
# SYS_EMAIL=admin@example.com
# SYS_PASSWORD=supersecretpassword